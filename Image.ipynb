{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, BatchSampler\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path\n",
    "# import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Layer, Dense, Lambda, \n",
    "                                     Dropout, Multiply, BatchNormalization, \n",
    "                                     Reshape, Concatenate, Conv2D, Permute)\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#Select GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: SET RANDOM SEEDS FOR REPRODUCIBILITY\n",
    "os.environ['PYTHONHASHSEED'] = str(420)\n",
    "import random\n",
    "random.seed(420)\n",
    "np.random.seed(420)\n",
    "tf.random.set_seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdbf9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=12288)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f947f8e",
   "metadata": {},
   "source": [
    "# Laod Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada10d0",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519bbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, train_size=0.5, random_state=420)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#Resize to 224x224\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'val samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Make TF Dataset\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "dataset=\"CIFAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(dataset, fn, batch_size=32):\n",
    "    dataset = dataset.map(fn)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56256b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(x, y):\n",
    "    \n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = Resizing(INPUT_SHAPE[0], INPUT_SHAPE[1], interpolation='nearest')(x)\n",
    "    x = tf.keras.applications.resnet50.preprocess_input(x)\n",
    "    \n",
    "    return (x, y)\n",
    "\n",
    "ds_train = batch_data(ds_train, reformat, BATCH_SIZE)\n",
    "ds_val = batch_data(ds_val, reformat, BATCH_SIZE)\n",
    "ds_test = batch_data(ds_test, reformat, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f32896",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('train_numpy.npy'):\n",
    "    print('Loading numpy arrays...')\n",
    "    train_numpy = np.load('train_numpy.npy')\n",
    "    print(train_numpy.shape)\n",
    "    val_numpy = np.load('val_numpy.npy')\n",
    "    print(val_numpy.shape)\n",
    "    test_numpy = np.load('test_numpy.npy')\n",
    "    print(test_numpy.shape)\n",
    "else:\n",
    "    train_numpy= [np.transpose(x[0].numpy(), (2,0,1)) for x, y in tqdm(ds_train)]\n",
    "    train_numpy = np.array(train_numpy)\n",
    "    print(train_numpy.shape)\n",
    "    val_numpy = [np.transpose(x[0].numpy(), (2,0,1)) for x, y in tqdm(ds_val)]\n",
    "    val_numpy = np.array(val_numpy)\n",
    "    print(val_numpy.shape)      \n",
    "    test_numpy = [np.transpose(x[0].numpy(), (2,0,1)) for x, y in tqdm(ds_test)]\n",
    "    test_numpy = np.array(test_numpy)\n",
    "    print(test_numpy.shape)\n",
    "    # Save the numpy arrays\n",
    "    np.save('train_numpy.npy', train_numpy)\n",
    "    np.save('val_numpy.npy', val_numpy)\n",
    "    np.save('test_numpy.npy', test_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcff61b",
   "metadata": {},
   "source": [
    "## Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dba032",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "LR = 1e-2\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "dataset=\"Imagenette\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'imagenette/full-size-v2',\n",
    "    split=['train', 'validation[:50%]', 'validation[-50%:]'],\n",
    "    as_supervised=False,\n",
    "    with_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(dataset, fn, batch_size=32):\n",
    "    dataset = dataset.map(fn)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d54888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(input_dict):\n",
    "    \n",
    "    i = input_dict['image']\n",
    "    i = tf.cast(i, tf.float32)\n",
    "    i = tf.image.resize_with_crop_or_pad(i, 224, 224)\n",
    "    i = tf.keras.applications.resnet50.preprocess_input(i)\n",
    "    \n",
    "    l = tf.one_hot(input_dict['label'], depth = 10)\n",
    "    \n",
    "    return (i, l)\n",
    "\n",
    "ds_train = batch_data(ds_train, reformat, BATCH_SIZE)\n",
    "ds_val = batch_data(ds_val, reformat, BATCH_SIZE)\n",
    "ds_test = batch_data(ds_test, reformat, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('cache/IMAGENETTE/train_numpy.npy'):\n",
    "    print('Loading numpy arrays...')\n",
    "    train_numpy = np.load('cache/IMAGENETTE/train_numpy.npy')\n",
    "    print(train_numpy.shape)\n",
    "    val_numpy = np.load('cache/IMAGENETTE/val_numpy.npy')\n",
    "    print(val_numpy.shape)\n",
    "    test_numpy = np.load('cache/IMAGENETTE/test_numpy.npy')\n",
    "    print(test_numpy.shape)\n",
    "else:\n",
    "    train_numpy= [np.transpose(x[0].numpy(), (2,0,1)) for x, y in tqdm(ds_train)]\n",
    "    train_numpy = np.array(train_numpy)\n",
    "    print(train_numpy.shape)\n",
    "    val_numpy = [np.transpose(x[0].numpy(), (2,0,1)) for x, y in tqdm(ds_val)]\n",
    "    val_numpy = np.array(val_numpy)\n",
    "    print(val_numpy.shape)\n",
    "    test_numpy = [np.transpose(x[0].numpy(), (2,0,1)) for x, y in tqdm(ds_test)]\n",
    "    test_numpy = np.array(test_numpy)\n",
    "    print(test_numpy.shape)\n",
    "    # Save the numpy arrays\n",
    "    np.save('cache/IMAGENETTE/train_numpy.npy', train_numpy)\n",
    "    np.save('cache/IMAGENETTE/val_numpy.npy', val_numpy)\n",
    "    np.save('cache/IMAGENETTE/test_numpy.npy', test_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8221bcc3",
   "metadata": {},
   "source": [
    "# Load Black-Box Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b1c29",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70caecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=False, weights='imagenet', \n",
    "    input_shape=INPUT_SHAPE, pooling='avg'\n",
    ")\n",
    "base_model.trainable = True\n",
    "\n",
    "model_input = Input(shape=INPUT_SHAPE, name='input')\n",
    "\n",
    "net = base_model(model_input)\n",
    "out = Dense(10, activation='softmax')(net)\n",
    "\n",
    "bb_model = Model(model_input, out)\n",
    "\n",
    "model_weights_path = 'MODEL/OM/model_weights.h5'\n",
    "\n",
    "bb_model.load_weights(model_weights_path)\n",
    "bb_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5c046",
   "metadata": {},
   "source": [
    "## Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "INPUT_SHAPE = (224,224,3)\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=True, weights='imagenet', \n",
    "    input_shape=INPUT_SHAPE\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model_input = Input(shape=INPUT_SHAPE, dtype='float32', name='input')\n",
    "\n",
    "net = base_model(model_input)\n",
    "out = Dense(10, activation='softmax')(net)\n",
    "\n",
    "bb_model = Model(model_input, out)\n",
    "\n",
    "model_weights_path = 'MODEL/OM/model_weights.h5'\n",
    "\n",
    "bb_model.load_weights(model_weights_path)\n",
    "bb_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5138f04",
   "metadata": {},
   "source": [
    "# LightningSHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ab203",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_STFS(model, loss_fn1, loss_fn2, data_loader, batch_size, num_samples, sampler, sampler_surr, paired_sampling, epoch):\n",
    "    #print('validate_STFS')\n",
    "    with torch.no_grad():\n",
    "        # Setup.\n",
    "        device = next(model.model.parameters()).device\n",
    "        mean_loss = 0\n",
    "        mean_loss1 = 0\n",
    "        mean_loss2 = 0\n",
    "        mean_loss3 = 0\n",
    "        mean_loss4 = 0\n",
    "        N = 0\n",
    "        link=nn.Softmax(dim=-1)\n",
    "\n",
    "        # COMPUTE NULL COALITION\n",
    "        sample=data_loader.dataset[0][0]\n",
    "        sample = sample.to(device)\n",
    "        zeros=torch.zeros(1, model.num_players, device=device)\n",
    "        zeros=model.resize(zeros)\n",
    "        null=model(sample, zeros)\n",
    "        null_reshape = null.reshape(1, -1, model.num_players)\n",
    "        null_reshape = null_reshape.permute(0, 2, 1)\n",
    "        null_sum = null_reshape.sum(dim=1)\n",
    "        null=link(null_sum)\n",
    "\n",
    "        # print(\"VALIDATION\")\n",
    "\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # Generate subsets.\n",
    "            S = sampler.sample(batch_size*num_samples, paired_sampling=paired_sampling).to(device=device)\n",
    "            S_surr = sampler_surr.sample(batch_size).to(device=device)\n",
    "\n",
    "            S_surr = model.resize(S_surr)\n",
    "\n",
    "            pred_xs = model(x, S_surr)\n",
    "            pred_xs_reshape = pred_xs.reshape(len(x), -1, model.num_players)\n",
    "            pred_xs_reshape = pred_xs_reshape.permute(0, 2, 1)\n",
    "            # print(\"pred_xs_reshape\",pred_xs_reshape.shape)\n",
    "            pred_xs_sum = pred_xs_reshape.sum(dim=1)\n",
    "\n",
    "            # print(\"pred_xs_sum\",pred_xs_sum.shape)\n",
    "            # print(\"y\",y.shape)\n",
    "\n",
    "            loss1 = loss_fn1(pred_xs_sum, y)\n",
    "\n",
    "            ones=torch.ones_like(S_surr).to(device)\n",
    "            pred=model(x, ones)\n",
    "            pred_reshape = pred.reshape(len(x), -1, model.num_players)\n",
    "            pred_reshape = pred_reshape.permute(0, 2, 1)\n",
    "            grand_sum = pred_reshape.sum(dim=1)\n",
    "            grand=link(grand_sum)\n",
    "            \n",
    "            pred_eff = additive_efficient_normalization(pred_reshape, y, null) ################### NORMALIZATION WITH Y\n",
    "            total=pred_eff.sum(dim=1)\n",
    "\n",
    "            x_tiled = x.unsqueeze(1).repeat(\n",
    "                1, num_samples, *[1 for _ in range(len(x.shape) - 1)]\n",
    "                ).reshape(batch_size * num_samples, *x.shape[1:])\n",
    "            \n",
    "            S1=model.resize(S)\n",
    "            val = model(x_tiled, S1)\n",
    "            val_reshape = val.reshape(len(x_tiled), -1, model.num_players)\n",
    "            val_reshape = val_reshape.permute(0, 2, 1)\n",
    "            val_sum = val_reshape.sum(dim=1)\n",
    "\n",
    "            values = link(val_sum)\n",
    "            \n",
    "            S=S.reshape(batch_size, num_samples, model.num_players)\n",
    "            values=values.reshape(batch_size, num_samples, -1)\n",
    "\n",
    "            approx = null + torch.matmul(S, pred_eff)\n",
    "            # loss2 = loss_fn2(approx, values)\n",
    "            loss4 = loss_fn2(y, grand)\n",
    "\n",
    "            loss1=loss1*10 # 100  \n",
    "            loss4=loss4*50 # 100\n",
    "                  \n",
    "            if epoch>=model.wait:\n",
    "                loss2 = loss_fn2(approx, values)\n",
    "                loss2 = loss2 * model.num_players\n",
    "                # loss4 = loss4 #* model.num_players\n",
    "                loss = loss1 + loss2 + loss4#*self.num_players\n",
    "                \n",
    "            else:\n",
    "                loss2 = 0\n",
    "                # loss4 = loss4 #* model.num_players\n",
    "                loss = loss1 + loss4\n",
    "        \n",
    "\n",
    "            N += len(x)\n",
    "            mean_loss += len(x) * (loss - mean_loss) / N\n",
    "            mean_loss1 += len(x) * (loss1 - mean_loss1) / N\n",
    "            mean_loss2 += len(x) * (loss2 - mean_loss2) / N\n",
    "            # mean_loss3 += len(x) * (loss3 - mean_loss3) / N\n",
    "            mean_loss4 += len(x) * (loss4 - mean_loss4) / N\n",
    "            \n",
    "    del loss1, loss2 #, loss4\n",
    "    return mean_loss, mean_loss1, mean_loss2, mean_loss4\n",
    "\n",
    "def generate_labels_STFS(dataset, model, batch_size):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Setup.\n",
    "        preds = []\n",
    "        if isinstance(model, torch.nn.Module):\n",
    "            device = next(model.parameters()).device\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "        for x in tqdm(loader):\n",
    "            pred = model(x.to(device)).cpu()\n",
    "            preds.append(pred)\n",
    "\n",
    "    return torch.cat(preds)\n",
    "\n",
    "def additive_efficient_normalization(pred, grand, null):\n",
    "    gap = (grand - null) - torch.sum(pred, dim=1)\n",
    "    return pred + gap.unsqueeze(1) / pred.shape[1]\n",
    "\n",
    "\n",
    "def multiplicative_efficient_normalization(pred, grand, null):\n",
    "    ratio = (grand - null) / torch.sum(pred, dim=1)\n",
    "    return pred * ratio.unsqueeze(1)\n",
    "\n",
    "\n",
    "class LightningSHAP:\n",
    "\n",
    "    def __init__(self, model, om, width, height, superpixel_size=1, groups=None):\n",
    "        # Store surrogate model.\n",
    "        self.model = model\n",
    "        self.batch_size = None\n",
    "        self.validation_batch_size = None\n",
    "        self.num_samples = None\n",
    "        self.link = None\n",
    "        self.bbm=om\n",
    "\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.supsize = superpixel_size\n",
    "        if superpixel_size == 1:\n",
    "            self.upsample = nn.Identity()\n",
    "        else:\n",
    "            self.upsample = nn.Upsample(\n",
    "                scale_factor=superpixel_size, mode='nearest')\n",
    "\n",
    "        self.small_width = width // superpixel_size\n",
    "        self.small_height = height // superpixel_size\n",
    "        self.num_players = self.small_width * self.small_height\n",
    "\n",
    "    def resize(self, S):\n",
    "        if len(S.shape) == 2:\n",
    "            S = S.reshape(S.shape[0], self.small_height, self.small_width).unsqueeze(1)\n",
    "        return self.upsample(S)\n",
    "                \n",
    "    def train_original_model(self,\n",
    "                             train_data,\n",
    "                             val_data,\n",
    "                             original_model,\n",
    "                             batch_size,\n",
    "                             max_epochs,\n",
    "                             loss_fn1,\n",
    "                             loss_fn2,\n",
    "                             validation_samples=1,\n",
    "                             validation_batch_size=None,\n",
    "                             lr=None,\n",
    "                             min_lr=None,\n",
    "                             lr_factor=None,\n",
    "                             weight_decay=None,\n",
    "                             lookback=None,\n",
    "                             num_samples=None,\n",
    "                             training_seed=None,\n",
    "                             validation_seed=None,\n",
    "                             paired_sampling=False,\n",
    "                             bar=False,\n",
    "                             verbose=False,\n",
    "                             debug=False,\n",
    "                             wait=0\n",
    "                             ):\n",
    "\n",
    "        # Set up train dataset.\n",
    "        if isinstance(train_data, np.ndarray):\n",
    "            # print('train_data numpy')\n",
    "            train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "\n",
    "        if os.path.isfile('Cifar10_224_TF_lables_train.pkl'):\n",
    "            print('Loading saved labels')\n",
    "            with open('Cifar10_224_TF_lables_train.pkl', 'rb') as f:\n",
    "                y_tr = pickle.load(f)\n",
    "        else:\n",
    "            y_tr = generate_labels_STFS(train_data, original_model, batch_size)\n",
    "            with open('Cifar10_224_TF_lables_train.pkl', 'wb') as f:\n",
    "                pickle.dump(y_tr, f)\n",
    "\n",
    "        if isinstance(train_data, torch.Tensor):\n",
    "            # print('train_data tensor')\n",
    "            train_set = TensorDataset(train_data, y_tr)\n",
    "        elif isinstance(train_data, Dataset):\n",
    "            # print('train_data dataset')\n",
    "            train_set = train_data\n",
    "        else:\n",
    "            raise ValueError('train_data must be either tensor or a PyTorch Dataset')\n",
    "\n",
    "        # Set up train data loader.\n",
    "        random_sampler = RandomSampler(train_set, replacement=True, num_samples=int(np.ceil(len(train_set) / batch_size))*batch_size)\n",
    "        batch_sampler = BatchSampler(random_sampler, batch_size=batch_size, drop_last=True)\n",
    "        train_loader = DataLoader(train_set, batch_sampler=batch_sampler, num_workers=4)\n",
    "\n",
    "        # Set up validation dataset.\n",
    "        sampler_surr=UniformSampler(self.num_players)\n",
    "        sampler = ShapleySampler(self.num_players)\n",
    "        if validation_seed is not None:\n",
    "            torch.manual_seed(validation_seed)\n",
    "\n",
    "        if validation_batch_size is None:\n",
    "            validation_batch_size = batch_size\n",
    "\n",
    "        if isinstance(val_data, np.ndarray):\n",
    "            # print('val_data numpy')\n",
    "            val_data = torch.tensor(val_data, dtype=torch.float32)\n",
    "\n",
    "        if isinstance(val_data, torch.Tensor):\n",
    "            if os.path.isfile('Cifar10_224_TF_lables_val.pkl'):\n",
    "                print('Loading saved labels')\n",
    "                with open('Cifar10_224_TF_lables_val.pkl', 'rb') as f:\n",
    "                    y_val = pickle.load(f)\n",
    "            else:\n",
    "                y_val = generate_labels_STFS(val_data, original_model, validation_batch_size)\n",
    "                with open('Cifar10_224_TF_lables_val.pkl', 'wb') as f:\n",
    "                    pickle.dump(y_val, f)\n",
    "            # y_val = generate_labels_STFS(val_data, original_model, validation_batch_size)\n",
    "            val_set = TensorDataset(val_data, y_val)\n",
    "        else:\n",
    "            raise ValueError('val_data must be either tuple of tensors or a PyTorch Dataset')\n",
    "\n",
    "        val_loader = DataLoader(val_set, batch_size=validation_batch_size, drop_last=True, num_workers=4)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_batch_size = validation_batch_size\n",
    "        self.num_samples = num_samples \n",
    "        self.wait=wait\n",
    "\n",
    "        # Setup for training.\n",
    "        link=nn.Softmax(dim=-1)\n",
    "        model = self.model\n",
    "        device = next(model.parameters()).device\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=lr_factor, patience=int(lookback // 2), min_lr=min_lr,verbose=verbose)\n",
    "        best_loss = 100000000\n",
    "        best_epoch = 0\n",
    "        best_model = deepcopy(model)\n",
    "        val_loss_list = []\n",
    "        val_loss1_list = []\n",
    "        val_loss2_list = []\n",
    "        train_loss_list = []\n",
    "        train_loss1_list = []\n",
    "        train_loss2_list = []\n",
    "        if training_seed is not None:\n",
    "            torch.manual_seed(training_seed)\n",
    "\n",
    "        print('OPT_training')\n",
    "        for epoch in range(max_epochs):\n",
    "            # Batch iterable.\n",
    "            if bar:\n",
    "                batch_iter = tqdm(train_loader, desc='Training epoch')\n",
    "            else:\n",
    "                batch_iter = train_loader\n",
    "\n",
    "            mean_loss = 0\n",
    "            mean_loss1 = 0\n",
    "            mean_loss2 = 0\n",
    "            mean_loss3 = 0\n",
    "            mean_loss4 = 0\n",
    "            N = 0\n",
    "\n",
    "            iter=0\n",
    "            for (x,y) in batch_iter:\n",
    "                iter+=1\n",
    "                # Prepare data.\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                # Generate subsets.\n",
    "                S = sampler.sample(batch_size*num_samples, paired_sampling=paired_sampling).to(device=device)\n",
    "                S_surr = sampler_surr.sample(batch_size).to(device=device)\n",
    "\n",
    "                if debug:\n",
    "                    print(\"x\",x.shape)\n",
    "                    print(\"S\",S.shape)\n",
    "                    print(\"S_surr\",S_surr.shape)\n",
    "                S_surr = self.resize(S_surr)\n",
    "                if debug:\n",
    "                    print(\"S_surr reshape\",S_surr.shape)\n",
    "                    print(\"y\",y.shape,y)\n",
    "\n",
    "                pred_xs = self.__call__(x, S_surr)\n",
    "                if debug:\n",
    "                    print(\"pred_xs\",pred_xs.shape)\n",
    "                pred_xs_reshape = pred_xs.reshape(len(x), -1, self.num_players)\n",
    "                if debug:\n",
    "                    print(\"pred_xs_reshape\",pred_xs_reshape.shape)\n",
    "                pred_xs_reshape = pred_xs_reshape.permute(0, 2, 1)\n",
    "                if debug:\n",
    "                    print(\"pred_xs permute\",pred_xs_reshape.shape)\n",
    "                pred_xs_sum = pred_xs_reshape.sum(dim=1)\n",
    "                if debug:   \n",
    "                    print(\"pred_xs_sum\",pred_xs_sum.shape)\n",
    "\n",
    "                loss1 = loss_fn1(pred_xs_sum, y)\n",
    "\n",
    "                # COMPUTE NULL COALITION\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    # zeros=torch.zeros(1, self.num_players, device=device)\n",
    "                    # if debug:\n",
    "                    #     print(\"zeros\",zeros.shape)\n",
    "                    # zeros=self.resize(zeros)\n",
    "                    # if debug:\n",
    "                    #     print(\"zeros reshape\",zeros.shape)\n",
    "                    zeros=torch.zeros_like(S_surr[0]).to(device)\n",
    "                    if debug:\n",
    "                        print(\"zeros\",zeros.shape)\n",
    "                    null=self.__call__(x[:1], zeros)\n",
    "                    if debug:\n",
    "                        print(\"null\",null.shape)\n",
    "                    null_reshape = null.reshape(1, -1, self.num_players)\n",
    "                    if debug:\n",
    "                        print(\"null reshape\",null_reshape.shape)\n",
    "                    null_reshape = null_reshape.permute(0, 2, 1)\n",
    "                    if debug:\n",
    "                        print(\"null permute\",null_reshape.shape)\n",
    "                    null_sum = null_reshape.sum(dim=1)\n",
    "                    null=link(null_sum)\n",
    "\n",
    "                self.model.train()\n",
    "                if debug:\n",
    "                    print(\"null\",null.shape)\n",
    "\n",
    "                ones=torch.ones_like(S_surr).to(device)\n",
    "                if debug:\n",
    "                    print(\"ones\",ones.shape)\n",
    "                # ones=self.resize(ones)\n",
    "                # print(\"ones reshape\",ones.shape)\n",
    "                pred=self.__call__(x, ones)\n",
    "                if debug:\n",
    "                    print(\"pred\",pred.shape)\n",
    "                pred_reshape = pred.reshape(len(x), -1,self.num_players)\n",
    "                if debug:\n",
    "                    print(\"pred_reshape\",pred_reshape.shape)\n",
    "                pred_reshape = pred_reshape.permute(0, 2, 1)\n",
    "                if debug:\n",
    "                    print(\"pred_reshape permute\",pred_reshape.shape)\n",
    "                grand_sum = pred_reshape.sum(dim=1)\n",
    "                grand=link(grand_sum)\n",
    "                if debug:\n",
    "                    print(\"grand\",grand.shape)\n",
    "                \n",
    "                pred_eff = additive_efficient_normalization(pred_reshape, y, null)\n",
    "                if debug:\n",
    "                    print(\"pred_eff\",pred_eff.shape)\n",
    "                total=pred_eff.sum(dim=1)\n",
    "                if debug:\n",
    "                    print(\"total\",total.shape)\n",
    "\n",
    "\n",
    "                x_tiled = x.unsqueeze(1).repeat(\n",
    "                    1, num_samples, *[1 for _ in range(len(x.shape) - 1)]\n",
    "                    ).reshape(batch_size * num_samples, *x.shape[1:])\n",
    "                if debug:\n",
    "                    print(\"x_tiled\",x_tiled.shape)\n",
    "\n",
    "                S1=self.resize(S)\n",
    "                if debug:\n",
    "                    print(\"S reshape\",S1.shape)\n",
    "                \n",
    "                val = self.__call__(x_tiled, S1)\n",
    "                if debug:\n",
    "                    print(\"val\",val.shape)\n",
    "                val_reshape = val.reshape(len(x_tiled), -1, self.num_players)\n",
    "                if debug:\n",
    "                    print(\"val_reshape\",val_reshape.shape)\n",
    "                val_reshape = val_reshape.permute(0, 2, 1)\n",
    "                if debug:\n",
    "                    print(\"val_reshape permute\",val_reshape.shape)\n",
    "                val_sum = val_reshape.sum(dim=1)\n",
    "\n",
    "                values = link(val_sum)\n",
    "                if debug:\n",
    "                    print(\"values\",values.shape)\n",
    "                \n",
    "                values=values.reshape(batch_size, num_samples, -1)\n",
    "                if debug:\n",
    "                    print(\"values reshape\",values.shape)\n",
    "                S=S.reshape(batch_size, num_samples, self.num_players)\n",
    "                if debug:\n",
    "                    print(\"S reshape\",S.shape)\n",
    "                \n",
    "                approx = null + torch.matmul(S, pred_eff)\n",
    "                if debug:\n",
    "                    print(\"approx\",approx.shape)\n",
    "\n",
    "                \n",
    "                loss4 = loss_fn2(y, grand)\n",
    "                loss4=loss4*50 # 100\n",
    "                loss1=loss1*10  \n",
    "\n",
    "                if epoch>=wait:\n",
    "                    loss2 = loss_fn2(approx, values)\n",
    "                    loss2 = loss2 * self.num_players\n",
    "                    # loss4 = loss4 #* self.num_players\n",
    "                    loss = loss1 + loss2 + loss4#*self.num_players\n",
    "                    \n",
    "                else:\n",
    "                    loss2 = 0\n",
    "                    # loss4 = loss4 #* self.num_players\n",
    "                    loss = loss1 #+ loss4\n",
    "            \n",
    "\n",
    "                N += len(x)\n",
    "                mean_loss += len(x) * (loss - mean_loss) / N\n",
    "                mean_loss1 += len(x) * (loss1 - mean_loss1) / N\n",
    "                mean_loss2 += len(x) * (loss2 - mean_loss2) / N\n",
    "                # mean_loss3 += len(x) * (loss3 - mean_loss3) / N\n",
    "                mean_loss4 += len(x) * (loss4 - mean_loss4) / N\n",
    "                \n",
    "\n",
    "                # Optimizer step.\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "\n",
    "            if epoch==wait:\n",
    "                print(\"reset best loss\")\n",
    "                best_loss=100000000\n",
    "\n",
    "            if verbose:\n",
    "                print('----- Epoch = {} -----'.format(epoch + 1))\n",
    "\n",
    "                if epoch>=wait:\n",
    "                    print('Train loss = {:.6f}'.format(mean_loss))\n",
    "                    print('Train loss1 = {:.6f}'.format(mean_loss1))\n",
    "                    print('Train loss2 = {:.6f}'.format(mean_loss2))\n",
    "                    print('Train loss4 = {:.6f}'.format(mean_loss4))\n",
    "                else:\n",
    "                    print('Train loss = {:.6f}'.format(mean_loss))\n",
    "                    print('Train loss1 = {:.6f}'.format(mean_loss1))\n",
    "                    print('Train loss4 = {:.6f}'.format(mean_loss4))\n",
    "                    # print('Train loss2 = {:.6f}'.format(mean_loss2))\n",
    "                    \n",
    "                print('')\n",
    "\n",
    "            # Evaluate validation loss.\n",
    "            self.model.eval()\n",
    "            val_loss, val_loss1, val_loss2, val_loss4 = validate_STFS(self, loss_fn1, loss_fn2, val_loader,  batch_size, num_samples, sampler, sampler_surr, paired_sampling, epoch)#.item()\n",
    "            self.model.train()\n",
    "\n",
    "            # Print progress.\n",
    "            if verbose:\n",
    "                #print('----- Epoch = {} -----'.format(epoch + 1))\n",
    "                if epoch>=wait:\n",
    "                    print('Val loss = {:.6f}'.format(val_loss))\n",
    "                    print('Val loss1 = {:.6f}'.format(val_loss1))\n",
    "                    print('Val loss2 = {:.6f}'.format(val_loss2))\n",
    "                    print('Val loss4 = {:.6f}'.format(val_loss4))\n",
    "                else:\n",
    "                    print('Val loss = {:.6f}'.format(val_loss))\n",
    "                    print('Val loss1 = {:.6f}'.format(val_loss1))\n",
    "                    print('Val loss4 = {:.6f}'.format(val_loss4))\n",
    "                print('')\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "            val_loss_list.append(val_loss)\n",
    "            val_loss1_list.append(val_loss1)\n",
    "            val_loss2_list.append(val_loss2)\n",
    "            train_loss_list.append(mean_loss)\n",
    "            train_loss1_list.append(mean_loss1)\n",
    "            train_loss2_list.append(mean_loss2)\n",
    "\n",
    "            # Check if best model.\n",
    "            if val_loss < best_loss and epoch>0:\n",
    "                best_loss = val_loss\n",
    "                best_model = deepcopy(model)\n",
    "                best_epoch = epoch\n",
    "                if verbose:\n",
    "                    print('\\t=> New best epoch, loss = {:.4f}'.format(val_loss))\n",
    "                    print('')\n",
    "            elif epoch - best_epoch == lookback:\n",
    "                if verbose:\n",
    "                    print('Stopping early')\n",
    "                break\n",
    "\n",
    "        # Clean up.\n",
    "        for param, best_param in zip(model.parameters(), best_model.parameters()):\n",
    "            param.data = best_param.data\n",
    "            \n",
    "        self.val_loss_list = val_loss_list\n",
    "        self.val_loss1_list = val_loss1_list\n",
    "        self.val_loss2_list = val_loss2_list\n",
    "        self.train_loss_list = train_loss_list\n",
    "        self.train_loss1_list = train_loss1_list\n",
    "        self.train_loss2_list = train_loss2_list\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "    def __call__(self, x, S):\n",
    "\n",
    "        return self.model((x,S))\n",
    "    \n",
    "\n",
    "    def shap_values(self, x, debug=False):\n",
    "\n",
    "        # Data conversion.\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        elif isinstance(x, torch.Tensor):\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('data must be np.ndarray or torch.Tensor')\n",
    "\n",
    "        # Ensure null coalition is calculated.\n",
    "        device = next(self.model.parameters()).device\n",
    "        link=nn.Softmax(dim=-1)\n",
    "        x=x.to(device)\n",
    "        \n",
    "        # Generate explanations.\n",
    "        with torch.no_grad():\n",
    "            # Calculate grand coalition (for normalization).\n",
    "            if debug:\n",
    "                print(\"x\",x.shape)\n",
    "            \n",
    "\n",
    "            # zeros=torch.zeros(1, self.num_players, device=device)\n",
    "            # print(\"zeros\",zeros.shape)\n",
    "            # zeros=self.resize(zeros)\n",
    "            # print(\"zeros\",zeros.shape)\n",
    "\n",
    "            zeros=torch.zeros(1, x.shape[-2], x.shape[-1], device=device)\n",
    "            if debug:\n",
    "                print(\"zeros\",zeros.shape)\n",
    "\n",
    "            # ones=torch.ones(x.shape[0], self.num_players, device=device)\n",
    "            # print(\"ones\",ones.shape)\n",
    "            # ones=self.resize(ones)\n",
    "            # print(\"ones\",ones.shape)\n",
    "\n",
    "            # ones=torch.ones_like(x).to(device)\n",
    "            ones=torch.ones(x.shape[0], 1, x.shape[-2], x.shape[-1], device=device)\n",
    "            if debug:\n",
    "                print(\"ones\",ones.shape)\n",
    "\n",
    "            null=self.__call__(x[0],zeros)\n",
    "            if debug:\n",
    "                print(\"null\",null.shape)\n",
    "            null_reshape = null.reshape(1, -1, self.num_players)\n",
    "            if debug:\n",
    "                print(\"null_reshape\",null_reshape.shape)\n",
    "            null_reshape = null_reshape.permute(0, 2, 1)\n",
    "            if debug:\n",
    "                print(\"null_reshape permute\",null_reshape.shape)\n",
    "            null_sum = null_reshape.sum(dim=1)\n",
    "            null=link(null_sum)\n",
    "            # if len(null.shape) == 1:\n",
    "            #     null = null.reshape(1, 1)\n",
    "\n",
    "            # ones=torch.ones(1, self.num_players, device=device)\n",
    "            # ones=torch.ones_like(zeros).to(device)\n",
    "            # match the dimensionality of the input\n",
    "            # ones=self.resize(ones\n",
    "            \n",
    "            # make ones of the follwing dimensionality(x.shape[0],1,x.shape[2],x.shape[3])\n",
    "            # ones=torch.ones(1, self.num_players, device=device)\n",
    "            # ones=self.resize(ones)\n",
    "\n",
    "\n",
    "\n",
    "            pred=self.__call__(x, ones)\n",
    "            if debug:\n",
    "                print(\"pred\",pred.shape)\n",
    "            image_shape=pred.shape\n",
    "            pred_reshape = pred.reshape(len(x), -1, self.num_players)\n",
    "            if debug:\n",
    "                print(\"pred_reshape\",pred_reshape.shape)\n",
    "            pred_reshape = pred_reshape.permute(0, 2, 1)\n",
    "            if debug:\n",
    "                print(\"pred_reshape permute\",pred_reshape.shape)\n",
    "            \n",
    "            # grand_sum = pred_reshape.sum(dim=1)\n",
    "            # grand=link(grand_sum)\n",
    "\n",
    "            y=self.bbm(x)\n",
    "\n",
    "            pred = pred_reshape #additive_efficient_normalization(pred_reshape, y, null)\n",
    "            # pred = additive_efficient_normalization(pred_reshape, y, null)\n",
    "\n",
    "            pred = pred.permute(0, 2, 1)\n",
    "            pred = pred.reshape(image_shape)\n",
    "\n",
    "        return pred.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e488c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils.fastshap\n",
    "import utils.unet\n",
    "reload(utils.unet)\n",
    "reload(utils.fastshap)\n",
    "from utils.unet import UNet\n",
    "from utils.fastshap import FastSHAP\n",
    "import utils.utils\n",
    "reload(utils.utils)\n",
    "from utils.utils import MaskLayer2d, KLDivLoss, DatasetInputOnly, UniformSampler, ShapleySampler, DatasetRepeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559496b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapperTFtoPT():\n",
    "    def __init__(self, model,device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # transform x from tensor to numpy\n",
    "        x = x.cpu().numpy()\n",
    "        pred=self.model.predict(np.transpose(x,(0,2,3,1)))\n",
    "        # transform pred from numpy to tensor\n",
    "        pred = torch.tensor(pred, dtype=torch.float32).to(self.device)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f211343",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = ModelWrapperTFtoPT(bb_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_tensor=torch.tensor(train_numpy, dtype=torch.float32)\n",
    "val_set_tensor=torch.tensor(val_numpy, dtype=torch.float32)\n",
    "train_set_tensor.shape, val_set_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningSHAP_Image_NN import ModifiedResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b10f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for model\n",
    "if os.path.isfile('Imagenette_LS_TF_N_x10_NS=4_L4_W2.pt'): ####################################################################\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load('Imagenette_LS_TF_N_x10_NS=4_L4_W2.pt').to(device)\n",
    "    lshap = LightningSHAP(explainer, original_model, width=224, height=224, superpixel_size=16)\n",
    "\n",
    "else:\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        MaskLayer2d(value=0, append=True),\n",
    "        # UNet(n_classes=10, num_down=2, num_up=1, num_convs=10, in_channels=4)\n",
    "        # Explainer18(num_classes=10, in_channels=4)\n",
    "        ModifiedResNet50(num_input_channels=4, num_classes=10, init_type='kaiming_uniform')\n",
    "    ).to(device)\n",
    "    \n",
    "    # print(explainer)\n",
    "    # original_model = nn.Sequential(bb_model, nn.Softmax(dim=1))\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    lshap = LightningSHAP(explainer, original_model, width=224, height=224, superpixel_size=16)\n",
    "\n",
    "    # Set up datasets\n",
    "    lshap_train = train_set_tensor \n",
    "    lshap_val = val_set_tensor\n",
    "\n",
    "    # Train\n",
    "    lshap.train_original_model(\n",
    "        lshap_train,\n",
    "        lshap_val,\n",
    "        original_model,\n",
    "        batch_size=64,\n",
    "        num_samples=4,\n",
    "        max_epochs=100,\n",
    "        paired_sampling=True,\n",
    "        # eff_lambda=1e-2,\n",
    "        loss_fn1=KLDivLoss(), #KLDivLoss(),\n",
    "        loss_fn2=nn.MSELoss(), #KLDivLoss(),\n",
    "        validation_samples=1,\n",
    "        lookback=10,\n",
    "        lr=2e-4,#2e-4\n",
    "        min_lr=1e-8,\n",
    "        weight_decay=1e-2, ######################################\n",
    "        lr_factor=0.5,\n",
    "        verbose=True,\n",
    "        debug=False,\n",
    "        bar=True,\n",
    "        wait=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b13dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save explainer\n",
    "explainer.cpu()\n",
    "torch.save(explainer, f'{dataset}_LS.pt')\n",
    "explainer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-thirty",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4062f",
   "metadata": {},
   "source": [
    "## Compute SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a64c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = os.path.join('', 'images')\n",
    "images = np.load(os.path.join(images_dir, 'processed_images.npy'), allow_pickle=True)\n",
    "labels = np.load(os.path.join(images_dir, 'labels.npy'), allow_pickle=True)\n",
    "predictions = np.load(os.path.join(images_dir, 'predictions.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af747a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_imgs = []\n",
    "labels2 = []\n",
    "for i, (x, y) in enumerate(ds_test):\n",
    "    processed_imgs.append(x.numpy())\n",
    "    labels2.append(y.numpy())\n",
    "    if i >= 999:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el1, el2 in zip(labels, labels2):\n",
    "    # print(el1, el2)\n",
    "    if el1 != np.argmax(el2):\n",
    "        print(el1, el2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9068a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el1, el2 in zip(images, processed_imgs):\n",
    "    if not np.allclose(el1, el2):\n",
    "        print('not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el1, el2 in zip(test_numpy[:1000], processed_imgs):\n",
    "    tmp=np.transpose(el2,(2,0,1))\n",
    "    if not np.allclose(el1, tmp):\n",
    "        print('not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_process = test_numpy[:1000]\n",
    "to_process = torch.tensor(to_process)\n",
    "to_process.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a804d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "values=lshap.shap_values(to_process.to(device))\n",
    "explaining_time = time.time() - t\n",
    "print(values.shape)\n",
    "values2 = np.repeat(values, 16, axis=2)\n",
    "values2 = np.repeat(values2, 16, axis=3)\n",
    "print(values2.shape)\n",
    "print(f\"Explaining time: {explaining_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f3a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"MODEL/LIGHTNINGSHAP\", 'explaining_time.pkl'), 'wb') as f:\n",
    "    pickle.dump(explaining_time, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b431104",
   "metadata": {},
   "outputs": [],
   "source": [
    "values3 = np.transpose(values2, (1, 0, 2, 3))\n",
    "values3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18798230",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"MODEL/LIGHTNINGSHAP\", 'shap_values.pkl'), 'wb') as f:\n",
    "    pickle.dump(values3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8ba7e",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db205a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2382500",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=[np.argmax(y.numpy()) for x, y in tqdm(ds_val)] #############################################\n",
    "targets=np.array(targets)[:1000]\n",
    "print(targets.shape)\n",
    "\n",
    "num_classes = np.max(targets) + 1\n",
    "num_classes\n",
    "\n",
    "inds_lists = [np.where(targets == cat)[0] for cat in range(num_classes)]\n",
    "inds = [np.random.choice(cat_inds) for cat_inds in inds_lists]\n",
    "print(inds)\n",
    "\n",
    "x=val_numpy[inds] ############################################\n",
    "y=targets[inds]\n",
    "\n",
    "x = torch.tensor(x)\n",
    "print(x.shape, y)\n",
    "\n",
    "pred=original_model(x.to(device)).cpu().data.numpy()\n",
    "\n",
    "values=lshap.shap_values(x.to(device))\n",
    "values.shape\n",
    "\n",
    "# upscale values from 10x10x14x14 to 10x10x224x224. use np.repeat for this\n",
    "values2 = np.repeat(values, 16, axis=2)\n",
    "values2 = np.repeat(values2, 16, axis=3)\n",
    "values2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_original_image_from_array(x, data_format='channels_last'):\n",
    "    mean = [103.939, 116.779, 123.68]\n",
    "\n",
    "    # Zero-center by mean pixel\n",
    "    if data_format == 'channels_first':\n",
    "        if x.ndim == 3:\n",
    "            x[0, :, :] += mean[0]\n",
    "            x[1, :, :] += mean[1]\n",
    "            x[2, :, :] += mean[2]\n",
    "        else:\n",
    "            x[:, 0, :, :] += mean[0]\n",
    "            x[:, 1, :, :] += mean[1]\n",
    "            x[:, 2, :, :] += mean[2]\n",
    "    else:\n",
    "        x[..., 0] += mean[0]\n",
    "        x[..., 1] += mean[1]\n",
    "        x[..., 2] += mean[2]\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        # 'BGR'->'RGB'\n",
    "        if x.ndim == 3:\n",
    "            x = x[::-1, ...]\n",
    "        else:\n",
    "            x = x[:, ::-1, ...]\n",
    "    else:\n",
    "        # 'BGR'->'RGB'\n",
    "        x = x[..., ::-1]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d4f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=restore_original_image_from_array(x.numpy(), data_format='channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(num_classes, num_classes + 1, figsize=(22, 20))\n",
    "\n",
    "for row in range(num_classes):\n",
    "    # Image\n",
    "    classes = ['Tench', 'English\\n Springer', 'Cassette\\n Player', 'Chain Saw', 'Church', 'French\\n Horn', 'Garbage\\n Truck', 'Gas Pump', 'Golf Ball', 'Parachute']\n",
    "    # classes = ['Gas Pump', 'Tench', 'English\\n Springer', 'Chain Saw', 'Church', 'French\\n Horn', 'Garbage\\n Truck', 'Golf Ball', 'Cassette\\n Player', 'Parachute']\n",
    "    im = x2[row]\n",
    "    im = im.transpose(1, 2, 0).astype(float)\n",
    "    if im.max() > 1.0:\n",
    "        im = im / 255.0\n",
    "    im = np.clip(im, a_min=0, a_max=1)\n",
    "    axarr[row, 0].imshow(im) #, vmin=0, vmax=1)\n",
    "    axarr[row, 0].set_xticks([])\n",
    "    axarr[row, 0].set_yticks([])\n",
    "    axarr[row, 0].set_ylabel('{}'.format(classes[y[row]]), fontsize=14)\n",
    "    \n",
    "    # Explanations\n",
    "    m = np.abs(values2[row]).max()\n",
    "    for col in range(num_classes):\n",
    "        axarr[row, col + 1].imshow(values2[row, col], cmap='seismic', vmin=-m, vmax=m)\n",
    "        axarr[row, col + 1].set_xticks([])\n",
    "        axarr[row, col + 1].set_yticks([])\n",
    "        if col == y[row]:\n",
    "            axarr[row, col + 1].set_xlabel('{:.2f}'.format(pred[row, col]), fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            axarr[row, col + 1].set_xlabel('{:.2f}'.format(pred[row, col]), fontsize=12)\n",
    "        \n",
    "        # Class labels\n",
    "        if row == 0:\n",
    "            axarr[row, col + 1].set_title('{}'.format(classes[y[col]]), fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638afd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
